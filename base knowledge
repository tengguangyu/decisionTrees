                                 决策树
优点：计算复杂度不高，输出结果易于理解，对于中间值得缺失不敏感，可以处理不相关特征数据。
缺点：可能会产生过度匹配问题。
在构造决策树时，需要解决的第一个问题就是，当前数据集上哪个特征在划分数据分类时起决定性作用。

-------------------决策树伪代码-------------------
检测数据集中的每个子项是否属于同一分类：
if so
	return 类标签；
else
	寻找划分数据集的最好特征
	划分数据集
	创建分支节点
		for每个划分的子集
			调用函数createBranch并增加返回结果到分支节点中
	return 分支节点
-------------------信息增益-------------------
划分数据集的大原则是将无序数据变得有序。在划分数据集之前之后的信息发生的变化成为信息增益，获得信息增益最高的特征就是最好的选择。
集合信息的度量方式成为香农熵或者简称为熵，被定义为信息的期望值。
信息增益是熵的减少或者是数据无序度的减少。
